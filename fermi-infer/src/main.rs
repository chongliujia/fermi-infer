// å¼•å…¥æˆ‘ä»¬è‡ªå®šä¹‰çš„æ¨¡å—ï¼ˆç”¨æ¥è§£å†³ Qwen3 æ—  Bias çš„é—®é¢˜ï¼‰
mod model_qwen3;
use model_qwen3::{Config, Qwen3Model};

use anyhow::{Error as E, Result};
use candle_core::{DType, Device, Tensor, IndexOp};
use candle_nn::VarBuilder;
use hf_hub::{api::sync::ApiBuilder, Repo, RepoType};
use tokenizers::Tokenizer;
use std::io::Write;

fn main() -> Result<()> {
    // 1. åŸºç¡€ç¯å¢ƒè®¾ç½®
    let device = device_setup()?;
    println!("ğŸš€ è¿è¡Œè®¾å¤‡: {:?}", device);

    // ==========================================
    // æŒ‡å®š Qwen3 å®˜æ–¹æ¨¡å‹ ID
    // ==========================================
    let model_repo_id = "Qwen/Qwen3-4B";
    
    println!("ğŸ“¥ æ­£åœ¨è¿æ¥ HuggingFace: {} ...", model_repo_id);
    let api = ApiBuilder::from_env().build()?;
    let repo = api.repo(Repo::new(model_repo_id.to_string(), RepoType::Model));

    // 2. ä¸‹è½½åŸºç¡€æ–‡ä»¶
    println!("ğŸ“¥ ä¸‹è½½ Config å’Œ Tokenizer...");
    let tokenizer_filename = repo.get("tokenizer.json")?;
    let config_filename = repo.get("config.json")?;

    // ==========================================
    // 3. ä¸‹è½½æƒé‡ (Qwen3-1.7B æ˜¯åˆ†ç‰‡æ–‡ä»¶)
    // ==========================================
    println!("ğŸ“¥ æ£€æµ‹åˆ°æ¨¡å‹ä¸ºåˆ†ç‰‡æ ¼å¼ï¼Œå¼€å§‹ä¸‹è½½æƒé‡...");
    let filenames = vec![
        repo.get("model-00001-of-00003.safetensors")?,
        repo.get("model-00002-of-00003.safetensors")?,
        repo.get("model-00003-of-00003.safetensors")?,
    ];
    println!("âœ… æƒé‡ä¸‹è½½å®Œæˆ");

    // ==========================================
    // 4. Config æ¸…æ´— (é˜²æ­¢ null æŠ¥é”™)
    // ==========================================
    println!("âš™ï¸ æ­£åœ¨è§£æé…ç½®æ–‡ä»¶...");
    
    let config_content = std::fs::read_to_string(config_filename)?;
    let mut config_value: serde_json::Value = serde_json::from_str(&config_content)?;

    if let Some(obj) = config_value.as_object_mut() {
        // è·å–ä¸Šä¸‹æ–‡é•¿åº¦ä½œä¸ºé»˜è®¤å€¼
        let default_window = obj.get("max_position_embeddings")
            .and_then(|v| v.as_u64())
            .unwrap_or(32768);

        // ä¿®å¤ sliding_window ä¸º null çš„æƒ…å†µ
        if let Some(sw) = obj.get("sliding_window") {
            if sw.is_null() {
                println!("âš ï¸  Config ä¿®å¤: å°† 'sliding_window' è®¾ä¸º {}", default_window);
                obj.insert(
                    "sliding_window".to_string(), 
                    serde_json::Value::Number(serde_json::Number::from(default_window))
                );
            }
        }
    }

    // âš ï¸ å…³é”®ç‚¹ï¼šä½¿ç”¨æˆ‘ä»¬è‡ªå®šä¹‰çš„ Config ç»“æ„ä½“è§£æ
    let config: Config = serde_json::from_value(config_value)?;

    // 5. åŠ è½½æƒé‡
    let dtype = if device.is_metal() { DType::F16 } else { DType::F32 };
    let vb = unsafe { VarBuilder::from_mmaped_safetensors(&filenames, dtype, &device)? };

    // 6. åˆå§‹åŒ–æ¨¡å‹ (ä½¿ç”¨è‡ªå®šä¹‰çš„ Qwen3Model)
    println!("ğŸ—ï¸ æ­£åœ¨æ„å»ºæ¨¡å‹æ¶æ„ (Custom Qwen3 No-Bias)...");
    let mut model = Qwen3Model::new(&config, vb)?;
    let tokenizer = Tokenizer::from_file(tokenizer_filename).map_err(E::msg)?;
    model.clear_kv_cache();

    // ==========================================
    // 7. æ„é€  Prompt
    // ==========================================
    let raw_prompt = "ä½ å¥½ï¼Œè¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯â€œç¬¬ä¸€æ€§åŸç†â€ã€‚";
    let prompt = format!(
        "<|im_start|>user\n{}<|im_end|>\n<|im_start|>assistant\n",
        raw_prompt
    );
    println!("ğŸ—£ï¸ Prompt: {:?}", prompt);

    let tokens = tokenizer.encode(prompt, false).map_err(E::msg)?;
    let input_ids = tokens.get_ids().to_vec();
    
    println!("ğŸ¤– å¼€å§‹æ¨ç†...");

    // --- é˜¶æ®µä¸€ï¼šé¢„å¡«å…… (Prefill) ---
    let mut input_tensor = Tensor::new(input_ids.clone(), &device)?.unsqueeze(0)?;
    let mut logits = model.forward(&input_tensor, 0)?; 
    let (_b, seq_len, _vocab) = logits.dims3()?;
    let mut last_token_logits = logits.i((0, seq_len - 1, ..))?;
    
    let mut generated_ids = vec![]; 
    apply_repeat_penalty(&mut last_token_logits, 1.1, &generated_ids)?;
    
    let mut next_token_id = last_token_logits.argmax(0)?.to_scalar::<u32>()?;
    generated_ids.push(next_token_id);

    print!("{}", tokenizer.decode(&[next_token_id], true).map_err(E::msg)?);
    std::io::stdout().flush()?;

    // --- é˜¶æ®µäºŒï¼šè§£ç å¾ªç¯ (Decode Loop) ---
    let max_new_tokens = 5096; 
    let mut current_pos = input_ids.len();

    for _ in 0..max_new_tokens {
        input_tensor = Tensor::new(&[next_token_id], &device)?.unsqueeze(0)?;
        // æ³¨æ„ï¼šoffset æ˜¯å½“å‰ç”Ÿæˆçš„æ€»é•¿åº¦
        logits = model.forward(&input_tensor, current_pos)?; 
        last_token_logits = logits.i((0, 0, ..))?;

        apply_repeat_penalty(&mut last_token_logits, 1.1, &generated_ids)?;

        next_token_id = last_token_logits.argmax(0)?.to_scalar::<u32>()?;
        generated_ids.push(next_token_id);
        
        let token_text = tokenizer.decode(&[next_token_id], true).map_err(E::msg)?;
        print!("{}", token_text);
        std::io::stdout().flush()?;

        // åœæ­¢ç¬¦æ£€æµ‹
        if let Some(eos) = tokenizer.token_to_id("<|endoftext|>") { if next_token_id == eos { break; } }
        if let Some(im_end) = tokenizer.token_to_id("<|im_end|>") { if next_token_id == im_end { break; } }
        
        current_pos += 1;
    }

    println!("\n\nâœ… å®Œæˆ");
    Ok(())
}

fn device_setup() -> Result<Device> {
    if cfg!(feature = "cuda") {
        return Ok(Device::new_cuda(0)?);
    } else if cfg!(feature = "metal") {
        return Ok(Device::new_metal(0)?);
    }
    Ok(Device::Cpu)
}

fn apply_repeat_penalty(logits: &mut Tensor, penalty: f32, context: &[u32]) -> Result<()> {
    let device = logits.device();
    let orig_dtype = logits.dtype();
    let logits_f32 = if orig_dtype == DType::F32 {
        logits.clone()
    } else {
        logits.to_dtype(DType::F32)?
    };
    let mut logits_vec = logits_f32.to_vec1::<f32>()?;
    let start_index = if context.len() > 64 { context.len() - 64 } else { 0 };
    for &token_id in &context[start_index..] {
        let idx = token_id as usize;
        if idx < logits_vec.len() {
            let v = logits_vec[idx];
            if v > 0.0 {
                logits_vec[idx] = v / penalty;
            } else {
                logits_vec[idx] = v * penalty;
            }
        }
    }
    let mut out = Tensor::from_vec(logits_vec, logits.shape(), device)?;
    if orig_dtype != DType::F32 {
        out = out.to_dtype(orig_dtype)?;
    }
    *logits = out;
    Ok(())
}
